{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe1180227b0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import json\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "from konlpy.tag import Mecab\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment bot "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "눈치 살살 살피면서 상대방 기분을 최대화해야 함.<br>\n",
    "<br>\n",
    "가능한 액션 :\n",
    "* 동조하기\n",
    "* 웃긴말 하기(아재 스탈)\n",
    "* 사과하기\n",
    "* 제시하기\n",
    "* 인사하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Hangulpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_vocab = ['ㄱ', 'ㄲ', 'ㄴ', 'ㄷ', 'ㄸ', 'ㄹ', 'ㅁ',\n",
    "                  'ㅂ', 'ㅃ', 'ㅅ', 'ㅆ', 'ㅇ', 'ㅈ', 'ㅉ', 'ㅊ', 'ㅋ', 'ㅌ', 'ㅍ', \n",
    "                  'ㅎ', 'ㅏ', 'ㅐ', 'ㅑ', 'ㅒ', 'ㅓ', 'ㅔ', 'ㅕ', 'ㅖ', 'ㅗ', 'ㅘ',\n",
    "                  'ㅙ', 'ㅚ', 'ㅛ', 'ㅜ', 'ㅝ', 'ㅞ', 'ㅟ', 'ㅠ', 'ㅡ', 'ㅢ', 'ㅣ',\n",
    "                  'ㄳ', 'ㄵ', 'ㄶ', 'ㄺ', 'ㄻ', 'ㄼ', 'ㄽ',';', '^',':',')','!','?',',',\n",
    "                  'ㄾ', 'ㄿ', 'ㅀ', 'ㅄ','<ALPHA>','<NUM>','<OTHER>']\n",
    "char_to_ix = {v:i for i,v in enumerate(char_vocab)}\n",
    "ix_to_char = {v:k for k,v in char_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_char(token, char_to_ix):\n",
    "    idxs=[]\n",
    "    for s in token:\n",
    "        if is_hangul(s):\n",
    "            # 음소 단위 분해\n",
    "            try:\n",
    "                emso = list(decompose(s))\n",
    "                if emso[-1]=='':\n",
    "                    emso.pop()\n",
    "            except:\n",
    "                emso = s\n",
    "            idxs.extend(list(map(lambda w: char_to_ix[w], emso)))\n",
    "        else:\n",
    "            candit=s\n",
    "            if s.isalpha():\n",
    "                candit='<ALPHA>'\n",
    "            elif s.isnumeric():\n",
    "                candit='<NUM>'\n",
    "            else:\n",
    "                candit='<OTHER>'\n",
    "\n",
    "            try:\n",
    "                idxs.append(char_to_ix[candit])\n",
    "            except:\n",
    "                idxs.append(char_to_ix['<OTHER>']) # '' 가 OTHER같이\n",
    "    #idxs = list(map(lambda w: to_ix[w], seq))\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    tensor = Variable(tensor)\n",
    "    if USE_CUDA: tensor = tensor.cuda()\n",
    "\n",
    "    return tensor, len(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NEGATIVE = (\"바보\", \"멍청\", \"멍충\", \"ㅂㅅ\", \"닥쳐\" ,\"ㅅㅂ\", \"시발\", \"ㄷㅈㄹ\", \"뒤질래\", \"빠가\", \"ㅡㅡ\", \"ㅆㅃ\", \"존못\",\"씨발\"\n",
    "            \"시벌\", \"아놔\", \"디질래\", \"시바\", \"시방\", \"ㄷㅊ\", \"바부\", \"으휴\", \"-_-\", \"뻐큐\", \"뻑\", \"별로\", \"별루\", \"별론\",'?','? ㄴㄴ',\n",
    "            \"에효\", \"에휴\",\"노노\",\"ㄴㄴ\", \"ㅗㅗ\", \"아니야\",\"아닌\", \"싫\", \"임마\", \"인마\", \"좌식\",\"시러\", \"돌았\", \"도랏\",';;', '??','?! 노노'\n",
    "            ,\"아오\",\"밥팅\",\"밥퉁\",\"바부\",\"답답\",\"장난하\", \"됐다\", \"됐어\", \"에혀\", \"때려\", \"자식\", \"짜식\" ,\"ㅎㅌㅊ\", \"하타취\",\n",
    "            \"쓋\", \"씟\", \"쒯\", \"혼날래\", \"멍추아\", \"멍처아\", \"혼난다\", \"빵꾸똥꾸\", \"떵꼬\", \"똥꼬\", \"아냐\", \"우씨\",\"존싫\",\"졸라 실어\",\n",
    "            \"우씌\", \"짜증나\", \"짱나\", \"확 씨\", \"확씨\", \"이걸 확\", \"죽을래\", \"죽는다\", \"빡치게\", \"십새\", \"새끼\", \"새키\",'어휴',\n",
    "            \"아는게 뭐야\", \"아는게 머야\", \"아는게뭐야\", \"아는게머야\", \"아는게 없어\", \"아는게없어\", \"아는겡버서\", \"얌마\",\"틀렸\",\"틀렷\",\n",
    "             \"데엄\", \"젠좡\", \"젠장\", \"새캬\", \"그만\", \"주글래?\", \"혼난다\", \"장난치냐\", \"최악\", \"ㄲㅈ\",\"ㅜㅜ\",\"ㅠㅠ\",\"ㅠㅠㅠㅠ\",\n",
    "           \"흠\", \"음\", \"엥\", \"킁\", \"크항\", \"크앙\", \"끄항\", \"끙\", \"또르르\", \"쩝\", \"뻑큐\", \"씨발\", \"씨뻘롬\", \"아오\",\"헐\",\"허얼,,\",\"어이없네\")\n",
    "\n",
    "POSITIVE = (\"짱이다\",\"짱이야\", \"올\", \"최고\", \"우와\", \"고마워\", \"ㄳ\", \"땡큐\", \"천재\", \"똑똑\",\"감사\" , \"괜찮\", \"오호\", \"오홍\", \"땅큐\", \"땅켜\",\n",
    "            \"괜춘\", \"쩐다\", \"쩔어\", \"굿\", \"굳\", \"ㅇㅋ\", \"예쁘다\", \"이쁘다\", \"멋있\", \"멋져\", \"멋있\", \"멋지다\", \"땡쓰\",\"땡스\",\"웅!!\",\"아하!\",\n",
    "            \"이뿌\", \"이쁘\", \"아름답\", \"ㅇㅇ\", \"웅\", \"그래\", \"그랩\", \"고뤠\",\"그랭\",\"좋다\",\"좋아\",\"잘했\",\"잘한다\", \"잘하\",\"고마워 ㅠㅠ\",\"힝 고마워\",\n",
    "            \"잘하네\",\"갠춘\",\"만족\",\"오와\",\"우오오\",\"우오와\", \"울지마\", \"쓸만\", \"ㄱㅊ\", \"좋네\", \"ㅅㅌㅊ\", \"상타\",\"죨라 좋다 ㅋ\",\"하이\",\"하잉\",\n",
    "            \"오키\",\"오케\", \"대단\", \"잘해\" ,\"힘내\", \"화이팅\", \"파이팅\", \"울지망\", \"뭐가미안\",\"뭐가 미안\", \"뭐가 죄송\",'고마워!','!!',\"안뇽\",\"헬로\",\n",
    "            \"뭐가죄송\",\"머가 죄송\", \"머가죄송\",\"머가 미안\", \"머가미안\", \"그려\", \"조아\", \"죠아\", \"됴아\",\"땅켜\",\"땡! 켜!\", \"맘에 들어\", \"유후\", \"꺄오\",\n",
    "            \"꺄올\", \"내 스탈\", \"내 스타일\", \"내스탈\", \"내스타일\", \"좋았어\", \"져아\", \"사랑\", \"좋지\",\"꺄!\",\"꺄~\",\"존좋\",\"존나 좋아\",\"안녕\",\"ㅎㅇ\",\n",
    "            \"맘에 들\", \"마음에 들어\", \"맘에들엉\", \"마음에들어\", \"맘에든\", \"맘에 든\", \"마음에 든\", \"마음에든\", \"고맙\",\"고마웡\", \"잘햇어\",\"안녕ㅋㅋ\",\n",
    "            \"잘있어~\",\"ㅎㅇ!!\",\"안녕!\",\n",
    "            \"ㅋㅋ\", \"ㅎㅎ\", \"하하\", \"허허\", \"헤헤\", \"헤헿\",\"헿\", \"핳\", \"크크\",\"앜\", \"호호\", \"히히\", \"키키\",\"ㅋㅋㅋㅋㅋ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(CharRNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers)\n",
    "        \n",
    "        self.linear1 = nn.Linear(hidden_size,64)\n",
    "        self.linear2 = nn.Linear(64,2)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        hidden = Variable(torch.zeros(self.n_layers, 1, self.hidden_size)) \n",
    "        \n",
    "        if USE_CUDA:\n",
    "            hidden = hidden.cuda()\n",
    "        \n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.gru(embedded.unsqueeze(1), hidden)\n",
    "        \n",
    "        l1 = F.relu(self.linear1(hidden.squeeze(1)))\n",
    "        out = F.log_softmax(self.linear2(l1))\n",
    "                \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=[]\n",
    "for n in NEGATIVE:\n",
    "    train.append([n,0])\n",
    "for p in POSITIVE:\n",
    "    train.append([p,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "263"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(len(char_to_ix),32)\n",
    "loss_function = nn.NLLLoss() \n",
    "optimizer= optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.339748994185\n",
      "0.280069474547\n",
      "0.0119279152984\n"
     ]
    }
   ],
   "source": [
    "for step in range(30):\n",
    "    losses=[]\n",
    "    for i, (sent, label) in enumerate(train):\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        model_input, length = prepare_char(sent,char_to_ix)\n",
    "        hypothesis = model(model_input)\n",
    "        loss = loss_function(hypothesis, Variable(torch.LongTensor([label])))\n",
    "        loss.backward()\n",
    "        losses.append(loss.data.tolist()[0])\n",
    "        \n",
    "        optimizer.step()\n",
    "    if step%10==0:\n",
    "        print(np.mean(losses))\n",
    "        random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.2031\n",
      "[torch.FloatTensor of size 1x1]\n",
      " Variable containing:\n",
      " 0\n",
      "[torch.LongTensor of size 1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_input, _ = prepare_char(test,char_to_ix)\n",
    "result = model(test_input)\n",
    "v,i = torch.max(result,1)\n",
    "print(v, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dsksd/.local/lib/python3.5/site-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type CharRNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'sent_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agree(sent):\n",
    "    reply = random.choice([\"맞아요\", \"그렇죠\",\"그러게 말이에요~\", \"그 맘 이해해요 ㅠㅠ\"])    \n",
    "    return reply\n",
    "\n",
    "def sorry(sent):\n",
    "    reply = random.choice([\"미안해요ㅠㅠ\",\"죄송해요ㅠ\"])\n",
    "    return reply\n",
    "\n",
    "def ask(sent):\n",
    "    reply = random.choice([\"어떤 고민이 있으신가요?\"])\n",
    "    return reply\n",
    "\n",
    "def request(sent):\n",
    "    reply = random.choice([\"좀 더 자세히 말해주실래요?\",\"좀 더 자세히 말해줘요!\"])\n",
    "    return reply\n",
    "\n",
    "def suggest(sent):\n",
    "    reply = random.choice([\"오 이건 어때요?\",\"이런거 어떠십니까?\"])\n",
    "    return reply\n",
    "\n",
    "def greeting(sent):\n",
    "    reply = random.choice([\"안녕!\"])\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_to_func = {0:agree, 1:sorry,2:ask,3:request,4:suggest,5:greeting}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOT :  안녕! Previous USER SENT :  0\n",
      "하이!\n",
      "USER :  하이!\n",
      "BOT :  어떤 고민이 있으신가요? Previous USER SENT :  1\n",
      "내 고민은~\n",
      "USER :  내 고민은~\n",
      "BOT :  안녕! Previous USER SENT :  1\n",
      "ㅎㅇ!\n",
      "USER :  ㅎㅇ!\n",
      "BOT :  안녕! Previous USER SENT :  1\n",
      "ㅡㅡ\n",
      "USER :  ㅡㅡ\n",
      "BOT :  좀 더 자세히 말해줘요! Previous USER SENT :  0\n",
      "ㅋㅋ웅\n",
      "USER :  ㅋㅋ웅\n",
      "BOT :  좀 더 자세히 말해주실래요? Previous USER SENT :  1\n",
      "머가\n",
      "USER :  머가\n",
      "BOT :  안녕! Previous USER SENT :  0\n",
      "굿\n",
      "USER :  굿\n"
     ]
    }
   ],
   "source": [
    "temp=[]\n",
    "user_reply= \" \"\n",
    "while(1):\n",
    "    done=False\n",
    "    try:\n",
    "        user_said = user_reply\n",
    "        user_input,_ = prepare_char(user_said,char_to_ix)\n",
    "        sent = model(user_input)\n",
    "        v,i = torch.max(sent,1)\n",
    "        reward = v.data.tolist()[0][0]\n",
    "        random_action = random.choice(range(6))\n",
    "        bot_said = reply_to_func[random_action](\"\")\n",
    "        print(\"BOT : \",bot_said, \"Previous USER SENT : \",i.data.tolist()[0][0])\n",
    "        user_reply = input()\n",
    "        print(\"USER : \", user_reply)\n",
    "        \n",
    "        if user_reply in [\"좋아\",\"맘에 들어\",\"굿\"]:\n",
    "            reward+=1.0\n",
    "            done=True\n",
    "        elif user_reply in [\"됐다\", \"그만하자\", \"에휴\"]:\n",
    "            reward+=-10.0\n",
    "            done=True\n",
    "        temp.append([user_said,random_action,reward,user_reply])\n",
    "        \n",
    "        if done:\n",
    "            exp.append(temp)\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(exp,open('explain_memory.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
